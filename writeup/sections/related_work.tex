\section{Related Work}
A review of the vast SLAM literature is beyond the scope of this
paper. For a thorough survey we refer to \cite{cadena2016}. The focus
of this section will be on SLAM or localization techniques that
operate off of fiducial markers.

Several works on this topic however do not employ graph based
optimizers. For instance, Ref. \cite{kayhani2019} presents a
Kalman-filter based approach for localizing off of multiple
AprilTags. The authors
use localization via tags for aerial construction surveillance because
often GPS signals are compromised by surrounding buildings. In further
contrast to TagSLAM, there is no mapping: all tag poses must be
entered into a map beforehand.

Ref. \cite{neunert2016} presents a visual-inertial approach for
obtaining ground truth positions from a combination of inertial
measurement unit (IMU) and camera. They also utilize April\-Tags, but in
contrast to TagSLAM use an Extended Kalman Filter (EKF), a method that
is well suited for their goal to effectively provide a real-time,
outdoor, low-cost motion capture system. Since TagSLAM uses a graph
optimizer instead of a filter, it can be operated in non-real time to
leverage observations from both the past and the future, resulting in
smoother trajectories. TagSLAM also does not require the presence of
an IMU and can work with cameras alone. This simplifies the
experimental setup, but also reduces robustness to motion blur during
quick rotations. In case IMU data is available, TagSLAM can be set up
to operate in a similar fashion to the system described in
\cite{neunert2016}. One could for example run a standard monocular VIO
algorithm without the use of any tags, and feed the computed odometry
updates into TagSLAM to be combined with AprilTag observations for
loop closure and drift removal.

A combination of AprilTags and GTSAM were used in
Ref.\ \cite{pfrommer2017} to provide ground truth for VIO
benchmarking. The software developed there served as a precursor to
TagSLAM, but it was lacking a framework for generalization to other
scenarios, and required that approximate tag world poses be available
beforehand.

Closely related to the present paper is the underwater SLAM performed
in \cite{westman2018}. The authors also leverage AprilTags and the
GTSAM factor graph optimizer to obtain vision based ground truth poses
and extrinsic calibration. The focus of their work however is more on
providing a solution for a particular problem, whereas TagSLAM aims to
be a general purpose framework that can be easily applied to many
different settings. In fact, all the factors in \cite{westman2018}
that are related to AprilTags are already implemented in TagSLAM. The
code structure of TagSLAM is designed such that adding the
problem-specific XHY and ZPR factors from \cite{westman2018} should be
straight forward.

Some of the difficulties with optimizer initialization discussed in
section \ref{sec:robustinit} have been nicely described in
Ref.\ \cite{jin2017}. The authors overcome these issues by using
additional depth sensor information. In contrast, TagSLAM leverages a
combination of multiple tags, multiple cameras, or pose history to
arrive at a robust starting guess. This works also outdoors or over
longer distances, where depth sensing is not an option.
